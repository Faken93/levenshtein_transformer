{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from torch import nn\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<PLH>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "encoder.resize_token_embeddings(len(tokenizer))  \n",
    "\n",
    "noop = \"N\"\n",
    "sub = \"S\"\n",
    "insert = \"I\"\n",
    "delete = \"D\"\n",
    "\n",
    "def ld(s1, s2, subcost=1, delcost=1, inscost=1):\n",
    "    operations = [[\"\" for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n",
    "    \n",
    "    matrix = np.zeros((len(s1)+1, len(s2)+1))\n",
    "    \n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0,j] = j\n",
    "        operations[0][j] = insert\n",
    "        for i in range(len(s1) + 1):\n",
    "            matrix[i,0] = i\n",
    "            operations[i][0] = insert\n",
    "            if i > 0 and j > 0:\n",
    "                subCost = matrix[i-1, j-1] if s1[i-1] == s2[j-1] else matrix[i-1, j-1] + subcost\n",
    "                insertCost = matrix[i, j-1] + inscost\n",
    "                deleteCost = matrix[i-1, j] + delcost\n",
    "                minCost = min(subCost, insertCost, deleteCost)\n",
    "                matrix[i,j] = minCost\n",
    "                if minCost == 0:\n",
    "                    operations[i][j] = noop\n",
    "                elif minCost == deleteCost:\n",
    "                    operations[i][j] = delete\n",
    "                elif minCost == insertCost:\n",
    "                    operations[i][j] = insert\n",
    "                elif minCost == subCost:\n",
    "                    operations[i][j] = sub\n",
    "    i = len(s1)\n",
    "    j = len(s2)\n",
    "    history = []\n",
    "    while j > 0 or i > 0:        \n",
    "        if delcost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i-1,j]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "        elif inscost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i,j-1]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append((insert,s2[j-1]))\n",
    "                #history.append(insert)\n",
    "                j -= 1\n",
    "    history.reverse()\n",
    "    return matrix, matrix[len(s1),len(s2)], history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "30523\n"
     ]
    }
   ],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, \"r\") as infile:\n",
    "            self.data = json.load(infile)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"Data\"])\n",
    "\n",
    "    def sample(self):\n",
    "        return self.data[\"Data\"][random.randint(0, len(self.data[\"Data\"]))][\"Question\"]\n",
    "    \n",
    "PLH = \"<PLH>\"\n",
    "TS = \"<s>\"\n",
    "TE = \"</s>\"\n",
    "\n",
    "class PlaceholderClassifier(nn.Module):\n",
    "    def __init__(self, hsz, max_placeholders=10):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(\n",
    "            hsz, max_placeholders,\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.activation(self.dense(input))\n",
    "    \n",
    "class TokenClassifier(nn.Module):    \n",
    "    def __init__(self, hsz, vsz, max_seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(\n",
    "            hsz, vsz\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.activation(self.dense(input))\n",
    "        \n",
    "class DeletionClassifier(nn.Module):    \n",
    "    def __init__(self, hsz):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(\n",
    "            hsz, 2,\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.activation(self.dense(input))\n",
    "dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "dataset.sample()\n",
    "plh = tokenizer.encode(\"<PLH>\")[0]\n",
    "print(plh)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[7592, 1010, 2026, 2171, 2003], [2054, 2003, 2115]],\n",
       " [[7592, 1010, 2026, 2171, 2003], [2054, 2003, 2115, 30522, 30522]],\n",
       " [[0, 0, 0, 0, 0], [0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deleted_indices_to_placeholders(deleted, max_placeholders):\n",
    "    print(\"max_placeholders\")\n",
    "    print(max_placeholders)\n",
    "    i = 0\n",
    "    placeholders = []\n",
    "    num_deleted = 0\n",
    "    while True:\n",
    "        if i == len(deleted):\n",
    "            if num_deleted > 0:\n",
    "                placeholders.append(min(num_deleted, max_placeholders))\n",
    "            break\n",
    "        if deleted[i] == 1:\n",
    "            num_deleted += 1\n",
    "        else:\n",
    "            if num_deleted > 0:\n",
    "                placeholders.append(min(num_deleted, max_placeholders))\n",
    "            placeholders.append(0)\n",
    "            num_deleted = 0\n",
    "        i += 1\n",
    "    while len(placeholders) < len(deleted):\n",
    "        placeholders.append(0)\n",
    "    return torch.unsqueeze(torch.LongTensor(placeholders), 0)\n",
    "\n",
    "def apply_deletions(y, deleted, pad=False):\n",
    "    batch_post_deletion = []\n",
    "    batch_post_deletion_with_placeholders = []\n",
    "    for batch_index in range(len(y)):\n",
    "        j = 0\n",
    "        post_deletion = []\n",
    "        post_deletion_with_placeholders = []\n",
    "        for i in range(len(y[batch_index])):\n",
    "            if deleted[batch_index][i] == 0:\n",
    "                post_deletion.append(y[batch_index][i])\n",
    "                post_deletion_with_placeholders.append(y[batch_index][i])\n",
    "                j += 1\n",
    "            else:\n",
    "                post_deletion_with_placeholders.append(plh)\n",
    "        batch_post_deletion.append(post_deletion)\n",
    "        batch_post_deletion_with_placeholders.append(post_deletion_with_placeholders)\n",
    "    return batch_post_deletion, batch_post_deletion_with_placeholders\n",
    "\n",
    "def delete_random(y, p=0.25, pad=True):\n",
    "    \"\"\"Deletes token(s) randomly from the passed (tokenized) string with probability p\n",
    "    Accepts:\n",
    "    - a list of token sequences bsz * pad_length\n",
    "    Returns tensors of:\n",
    "    - the token sequence post-deletion\n",
    "    - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "    - the number of placeholders inserted at each post-deletion index\n",
    "    \"\"\"\n",
    "    batch_deletions = []\n",
    "    for i in range(len(y)):\n",
    "        deletions = []\n",
    "        for i in range(len(y[i])):\n",
    "            if random.random() < p:\n",
    "                deletions.append(1)\n",
    "            else:\n",
    "                deletions.append(0)\n",
    "        batch_deletions.append(deletions)\n",
    "    post_deletion, post_deletion_with_placeholders = apply_deletions(y, batch_deletions)\n",
    "\n",
    "    return post_deletion, post_deletion_with_placeholders, batch_deletions#,placeholders\n",
    "\n",
    "delete_random([tokenizer.encode(\"Hello, my name is \"), tokenizer.encode(\"What is your name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_minimal(y, y_ground, pad=True, max_placeholders=0):\n",
    "    \"\"\"Apply the sequence of deletions from y that give the smallest possible Levenshtein distance from y_ground\n",
    "    Returns tensors of:\n",
    "    - the token sequence post-deletion\n",
    "    - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "    - the number of placeholders inserted at each post-deletion index\n",
    "    \"\"\"\n",
    "    batched = torch.zeros(len(y),)\n",
    "    \n",
    "    # if y_ground is longer than y, there is no sequence of deletes with a shorter distance\n",
    "    if len(y_ground) > len(y): \n",
    "        return y\n",
    "    \n",
    "    # calculate LD directly against tokens\n",
    "    deleted = []\n",
    "    matrix, dist, edits = ld(y.numpy(),y_ground.numpy(), subcost=np.inf, inscost=np.inf)\n",
    "    num_deleted = 0\n",
    "    for i in range(len(edits)):\n",
    "        if edits[i] == \"D\":\n",
    "            deleted.append(1)\n",
    "            num_deleted += 1\n",
    "        else:\n",
    "            deleted.append(0)\n",
    "    placeholders = deleted_indices_to_placeholders(deleted,max_placeholders=max_placeholders)\n",
    "    post_deletion, post_deletion_with_placeholders = deleted_boolean_to_tensors(y, deleted, num_deleted)    \n",
    "    return post_deletion, post_deletion_with_placeholders, torch.LongTensor([deleted])#,placeholders\n",
    "\n",
    "def pad(items, pad_len=0, pad_token=0):\n",
    "    if pad_len == 0:\n",
    "        pad_len = max([len(i) for i in items])\n",
    "    for i in items:\n",
    "        while len(i) < pad_len:\n",
    "            i.append(pad_token)\n",
    "    return items\n",
    "    \n",
    "def insert_minimal(y, y_ground,max_placeholders):\n",
    "    \"\"\"Apply the sequence of insertions to y resulting in the smallest possible Levenshtein distance from y_ground\n",
    "    Accepts tensor of:\n",
    "    - bsz * max_seq_len\n",
    "    Returns tensors of:\n",
    "    - size (n+1), where the value at position 0 <= i < n represents the number of PLH tags inserted at that position\n",
    "        - n is the number of tokens in y\n",
    "    - size(k) containing the indices of each inserted token, where k is the total number of tokens added\n",
    "    - size(n+k) containing the tokens of the entire post-insertion sequence\n",
    "    \"\"\"\n",
    "\n",
    "    batch_placeholders = []\n",
    "    batch_inserted = []\n",
    "    batch_new = []\n",
    "    for batch_idx in range(len(y)):\n",
    "        matrix, dist, edits = ld(y[batch_idx],y_ground[batch_idx], subcost=np.inf, delcost=np.inf)\n",
    "        inserted = 0\n",
    "        y_placeholders = []\n",
    "        y_inserted = []\n",
    "        y_new = []\n",
    "        y_idx = 0\n",
    "        i = 0\n",
    "        while i < len(edits):\n",
    "            if edits[i][0] == \"I\":\n",
    "                accum = 0\n",
    "                while i < len(edits) and edits[i][0] == \"I\":\n",
    "                    y_inserted.append(edits[i][1])\n",
    "                    y_new.append(edits[i][1])\n",
    "                    accum += 1\n",
    "                    i += 1\n",
    "                y_placeholders.append(min(accum,max_placeholders-1))\n",
    "            else:\n",
    "                y_placeholders.append(0)\n",
    "                y_new.append(y[batch_idx][y_idx])\n",
    "                i += 1\n",
    "                y_idx += 1\n",
    "        batch_placeholders.append(y_placeholders)\n",
    "        batch_inserted.append(y_inserted)\n",
    "        batch_new.append(y_new)\n",
    "    batch_placeholders = pad(batch_placeholders, pad_token=tokenizer.pad_token_id)\n",
    "    #batch_inserted = pad(batch_inserted)\n",
    "    batch_new = pad(batch_new, pad_token=tokenizer.pad_token_id)\n",
    "    \n",
    "    return batch_placeholders, batch_inserted, torch.LongTensor(batch_new)\n",
    "\n",
    "y1 = tokenizer.encode(\"My name is Nick, what is your name\")\n",
    "y2 = tokenizer.encode(\"My name is Nick\")\n",
    "y3 = tokenizer.encode(\"What's the dog bro you say now\")\n",
    "y4 = tokenizer.encode(\"What's the\")\n",
    "\n",
    "#delete_minimal(torch.LongTensor([y1]), torch.LongTensor([y2]))\n",
    "#insert_minimal([y2,y4], [y1,y3])\n",
    "#y = torch.LongTensor([tokenizer.encode(\"Hi dude My name is Nick what name\")])\n",
    "#y_ground = torch.LongTensor([tokenizer.encode(\"My name is Nick, what is your name\")])\n",
    "\n",
    "#placeholders, inserted, new = insert_minimal(y, y_ground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "50\n",
      "tensor(12.6091, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what was adopted as the official motto of the united states in 1956?\n",
      "y_del\n",
      "##virեberriesե [unused168]aneous walk regattaaneousφ regatta special topicsե\n",
      "y_ins\n",
      "what was as the official motto of united states in [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2054,  2001,  4233,  2004,  1996,  2880, 12652,  1997,  1996,  2142,\n",
      "          2163,  1999,  3838,  1029]])\n",
      "torch.Size([1, 14])\n",
      "Decode step 1\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646, 17538,  2054,  3646,  2001, 17538, 17538,  4233, 17538, 17538,\n",
      "          2004, 17538, 17538,  3646, 17538,  1996, 17538, 17538, 17538, 17538,\n",
      "          2880, 29726, 17538, 12652, 17538,  1997, 17538, 17538, 17538, 17538,\n",
      "          1996, 17538, 17538, 17538, 17538,  2142, 17538, 17538,  2163, 17538,\n",
      "          1999,  3646,  3838, 14540, 17538,  1029]])\n",
      "torch.Size([1, 46])\n",
      "Decode step 2\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646, 17538,  3646,  3646,  2054,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  2001,  3646,  3646, 17538,\n",
      "          3646,  3646, 17538,  3646, 14884,  4233,  3646, 17538, 17538,  3646,\n",
      "          3646, 17538, 17538,  3646,  2004,  3646,  3646, 17538,  3646,  3646,\n",
      "         17538,  3646,  3646,  3646]])\n",
      "torch.Size([1, 44])\n",
      "Decode step 3\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646, 17538,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  2054,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646]])\n",
      "torch.Size([1, 60])\n",
      "Decode step 4\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 5\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 6\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 7\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 8\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 9\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 42])\n",
      "Decode step 10\n",
      "[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]\n",
      "1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "100\n",
      "tensor(12.5453, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "where in the human body are the deltoid muscles?\n",
      "y_del\n",
      "sheila sheila [unused95] currency loose rams sheilanchncherre sheilanch\n",
      "y_ins\n",
      "where in the human body the muscles? [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[2073, 1999, 1996, 2529, 2303, 2024, 1996, 3972, 3406, 3593, 6650, 1029]])\n",
      "torch.Size([1, 12])\n",
      "Decode step 1\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[  585,   585,  2073,   664,   585,  1999,   585, 25867, 17538,   585,\n",
      "          1996,   585,   585,  2529, 14540,   585,  2303,   585,   585,  2024,\n",
      "           585,   585, 17538,   585,  1996,   585, 19104,  3972,   585,   585,\n",
      "           585,   585,  3406, 14540,   585,   585,   585,  3593,   585,   585,\n",
      "          6650,   585,   585,  1029]])\n",
      "torch.Size([1, 44])\n",
      "Decode step 2\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[12966, 12966,   585, 12966, 12966,   585, 12966, 12966,  2073,   585,\n",
      "           585,   664, 22247,   585,   585,   585,   585,  1999,   585,   585,\n",
      "           585,   585,   585, 25867,   585, 25867, 17538, 12966, 12966,   585,\n",
      "           585, 12966, 12966,   585,  1996, 12966, 12966,   585]])\n",
      "torch.Size([1, 38])\n",
      "Decode step 3\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[12966, 14540, 12966, 23003, 12966, 12966, 12966, 12966,   585, 12966,\n",
      "         12966, 12966,   585, 14540, 12966, 14540, 14540,   585, 14540, 14540,\n",
      "         12966, 14540, 12966, 12966, 12966,   585,  2073, 14540, 14540,   585,\n",
      "         14540, 14540,   585, 14540, 14540,   664]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 4\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[28782, 23003, 12966, 23003, 23003, 14540, 23003, 23003, 12966, 17780,\n",
      "         17780, 23003, 17780, 17780, 12966, 17780, 17538, 12966, 17538, 17538,\n",
      "         12966, 17780, 17780, 12966, 17780, 17780,   585, 17780, 17780, 12966,\n",
      "         17780, 17780, 12966, 17780, 17780, 12966]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 5\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[17538, 17538, 28782, 17538, 17538, 23003, 17538, 17538, 12966, 17538,\n",
      "         17538, 23003, 17538, 17538, 23003, 17538, 17538, 14540, 17538, 17538,\n",
      "         23003, 17538, 17538, 23003, 15183, 23001, 12966, 17538, 17538, 17780,\n",
      "         17538, 17538, 17780, 17538, 17538, 23003]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 6\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[  585,   585, 17538,   585,   585, 17538,   585,   585, 28782,   585,\n",
      "           585, 17538,   585,   585, 17538,   585,   585, 23003,   585,   585,\n",
      "         17538,   585,   585, 17538,   585,   585, 12966,   585,   585, 17538,\n",
      "           585,   585, 17538,   585,   585, 23003]])\n",
      "torch.Size([1, 36])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 7\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[12966, 12966,   585, 12966, 12966,   585, 12966, 12966, 17538, 12966,\n",
      "         12966,   585, 12966, 12966,   585, 12966,   585, 17538, 14540, 14540,\n",
      "           585,   585, 14540,   585, 14540, 14540, 14540, 28782, 12966,   585,\n",
      "           585, 12966, 12966,   585,   585, 12966, 17538]])\n",
      "torch.Size([1, 37])\n",
      "Decode step 8\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[28782, 23003, 12966, 23003, 23003, 12966, 23003, 23003,   585, 17538,\n",
      "         17780, 12966,   585,   585, 12966,   585,   585,   585, 17538, 28782,\n",
      "         12966, 17780, 17780, 12966, 17780, 17780, 17538, 17780, 17780, 12966,\n",
      "         17780, 17780, 12966, 17780, 17780,   585]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 9\n",
      "torch.Size([1, 12, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[12966, 17538, 28782, 17538, 17538, 23003, 17538, 17538, 12966, 17538,\n",
      "         17538, 23003,   585, 17538, 23003, 17538, 17538, 12966, 17538, 17538,\n",
      "         23003, 17538, 17538, 23003, 17538, 17538,   585, 17538, 17538, 17538,\n",
      "         17538, 17538, 17780, 17538, 17538, 12966]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 10\n",
      "[585, 585, 12966, 585, 585, 17538, 585, 585, 28782, 585, 585, 17538, 585, 585, 17538, 585, 585, 23003, 585, 585, 17538, 585, 585, 17538, 585, 17538, 12966, 585, 585, 17538, 585, 585, 17538, 585, 585, 23003]\n",
      "[unused580] [unused580] cao [unused580] [unused580] rubble [unused580] [unused580] shamrock [unused580] [unused580] rubble [unused580] [unused580] rubble [unused580] [unused580] hades [unused580] [unused580] rubble [unused580] [unused580] rubble [unused580] rubble cao [unused580] [unused580] rubble [unused580] [unused580] rubble [unused580] [unused580] hades\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "150\n",
      "tensor(12.5162, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "following the battle of borodino, fire raged for four days, destroying an estimated three - quarters of which city?\n",
      "y_del\n",
      "binoculars mirrored mirrored za kerr hades reclamationene sparta [unused580] 坂ե melancholy [unused580]ե binoculars thwarted mirrored melancholy amusing thwarted hades za ferreira\n",
      "y_ins\n",
      "following battle ofrodino fire for four days an three - which? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2206,  1996,  2645,  1997,  8945, 14127,  5740,  1010,  2543, 28374,\n",
      "          2005,  2176,  2420,  1010,  9846,  2019,  4358,  2093,  1011,  7728,\n",
      "          1997,  2029,  2103,  1029]])\n",
      "torch.Size([1, 24])\n",
      "Decode step 1\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3646,  2206,  3646,  1996,  2645,  3646,  1997,  3646,  8945,  3646,\n",
      "         14127,  5740,  1010,  2543, 28374,  3646,  3646,  2005,  3646,  3646,\n",
      "          2176,  3646,  3646,  2420,  1010,   585,  9846,  3646,  3646, 14884,\n",
      "         14884,  2019,  3646,  4358,  3646,  2093, 16284,  1011,  3646,  3646,\n",
      "          7728,  3646,  1997,  2029,  3646,  7272, 18415,  3646,  2103,  3807,\n",
      "          1029]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 2\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646,  3646,  2206,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  1996,  3646,  2645,  3646,  3646,  3646,  3646,\n",
      "          1997,  3646,  3646,  3646,  3646,  3646,  3646,  8945,  3646,  3646,\n",
      "          3646, 14127,  3646,  5740,  3646,  3646,  3646,  3646,  1010,  3646,\n",
      "          2543,  3646,  3646, 28374,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  2005,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  2176,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  2420]])\n",
      "torch.Size([1, 84])\n",
      "Decode step 3\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 2206, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 1996, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 2645, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 1997, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 120])\n",
      "Decode step 4\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n",
      "Decode step 5\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n",
      "Decode step 6\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n",
      "Decode step 7\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n",
      "Decode step 8\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 9\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]])\n",
      "torch.Size([1, 72])\n",
      "Decode step 10\n",
      "[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]\n",
      "1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200\n",
      "tensor(12.5121, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "according to 2014 twitter statistics, how many million tweets are sent every day?\n",
      "y_del\n",
      "##եեեեե hades hadesեե mirroredե awaitedե hades ferreira mirrored ferreira\n",
      "y_ins\n",
      "to 2014 how many tts are sent day? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2429,  2000,  2297, 10474,  6747,  1010,  2129,  2116,  2454,  1056,\n",
      "         28394,  3215,  2024,  2741,  2296,  2154,  1029]])\n",
      "torch.Size([1, 17])\n",
      "Decode step 1\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2429, 19142,  2000, 23003,  2297, 10474,  6747,  1010,  2129, 23003,\n",
      "          2116,  2454,  1056, 28394,  3215,  2024,  2741, 29770, 29770,  2296,\n",
      "         17538, 15635,  2154,  1029]])\n",
      "torch.Size([1, 24])\n",
      "Decode step 2\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[28782, 17538,  2429, 23003, 19142, 17538, 17538,  2000, 17538, 17538,\n",
      "         23003, 23003,  2297, 17538, 17538, 10474, 17538, 17538,  6747, 17538,\n",
      "          1010, 17538,  2129, 17538, 23003, 17538, 17538,  2116, 17538, 17538,\n",
      "          2454, 17538, 29546,  1056, 28394,  3215, 14540,  2024, 17538, 17538,\n",
      "          2741]])\n",
      "torch.Size([1, 41])\n",
      "Decode step 3\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[  585,  3646,  3646, 28782,  3646, 17538,  2429,  3646, 23003,   585,\n",
      "         19142,  3646, 17538, 17538,   585,  2000,  3646,   585, 17538, 15724,\n",
      "          3646, 17538,  3646, 17538, 23003,   585, 27250, 23003,  2297, 17538,\n",
      "         15183, 17538, 17538, 17780, 17538,  3646, 17538, 10474,   585,  3646,\n",
      "         17538]])\n",
      "torch.Size([1, 41])\n",
      "Decode step 4\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,   585,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646, 28782,  3646,  3646,  3646,  3646,  3646, 17538,  3646,  3646,\n",
      "          2429,  3646,  3646,  3646,  3646,  3646, 23003,  3646,  3646,   585,\n",
      "          3646,  3646, 19142,  3646,  3646,  3646,  3646,  3646, 17538, 12966,\n",
      "         12966, 17538, 12966, 12966,   585, 12966,  3646,  2000,  3646,  3646,\n",
      "          3646,  3646,  3646]])\n",
      "torch.Size([1, 53])\n",
      "Decode step 5\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,   585,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646, 28782,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646]])\n",
      "torch.Size([1, 59])\n",
      "Decode step 6\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646,  585, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646]])\n",
      "torch.Size([1, 61])\n",
      "Decode step 7\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 8\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 9\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 10\n",
      "[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]\n",
      "1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "250\n",
      "tensor(12.4268, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what term is used to describe the furthest point of the moon from the earth?\n",
      "y_del\n",
      "influenza dusty dusty gradedibility bmg condition 255 255 255 regatta therapist 255 255 poems triumphorough\n",
      "y_ins\n",
      "term is used to the furthest point of the moon from earth? [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2054,  2744,  2003,  2109,  2000,  6235,  1996,  6519, 20515,  2391,\n",
      "          1997,  1996,  4231,  2013,  1996,  3011,  1029]])\n",
      "torch.Size([1, 17])\n",
      "Decode step 1\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2054,  2744, 28782, 17538, 12966, 12966,  2003, 12966, 12966,  1978,\n",
      "         17538,  2109, 23003,  2000,  6235,  1996, 17538, 18815,  6519, 23003,\n",
      "         17538, 20515, 12727, 23564,  2391,  1997,  1996, 17538, 17538,  4231,\n",
      "         23003, 17538,  2013,  1996,  3011,  1029]])\n",
      "torch.Size([1, 36])\n",
      "Decode step 2\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[21061,  2054,  2744, 21061, 28782, 21061, 17538, 12966, 12966,  2003,\n",
      "         12966, 12966, 23003,  1978, 10911, 17538, 23003,  2109, 23003, 23003,\n",
      "         21061,  2000,  6235, 21061,  1996,  1978, 17538]])\n",
      "torch.Size([1, 27])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 3\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[23001,  9826, 21061,  9826,  9826,  2054,  2744, 21061, 23001,  9826,\n",
      "         28782, 14884, 17538, 21061, 14884, 14884, 17538, 12966, 12966,  2003,\n",
      "         12966, 12966, 23003, 23001, 23001,  1978, 14884, 23001, 10911, 23001,\n",
      "         15183, 17538, 23001, 23001, 23003]])\n",
      "torch.Size([1, 35])\n",
      "Decode step 4\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[12966,  3646, 23001,  3646, 12966, 12966,  9826,  2345,  3646,  2345,\n",
      "         21061, 12966,  2345,  3646,  9826, 14540, 14540, 14540,  9826, 14540,\n",
      "         14540,  2054, 14540, 14540,  2744,  2345, 14540, 21061,  2345, 14540,\n",
      "         23001,  2345,  2345, 14540,  9826, 14540, 14540, 14540, 28782, 14540,\n",
      "         14540, 14540, 14884, 14540, 14540, 14540, 17538, 14540, 14540, 14540,\n",
      "         21061, 17780, 14540, 17780, 14884, 17780, 17780, 14540, 14884, 17780,\n",
      "         17780,  2345, 17538]])\n",
      "torch.Size([1, 63])\n",
      "Decode step 5\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646, 12966,  3646,  3646,  3646,  3646,  3646, 23001,  3646,\n",
      "          3646,  3646,  3646,  3646, 12966,  3646,  3646, 12966,  3646,  3646,\n",
      "          9826,  3646, 17538,  2345, 17538, 23001,  3646, 17538, 17538,  2345,\n",
      "          3646,  3646, 21061,  3646,  3646, 12966,  3646,  3646,  2345,  3646,\n",
      "          3646,  3646,  3646,  3646,  9826,  3646,  3646, 14540,  3646,  3646,\n",
      "         14540]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 6\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "         12966,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "         23001,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646, 12966,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646]])\n",
      "torch.Size([1, 65])\n",
      "Decode step 7\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646, 12966,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,  3646,\n",
      "          3646,  3646,  3646,  3646,  3646,  3646,  3646]])\n",
      "torch.Size([1, 57])\n",
      "Decode step 8\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 9\n",
      "torch.Size([1, 17, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646,\n",
      "         3646, 3646, 3646]])\n",
      "torch.Size([1, 51])\n",
      "Decode step 10\n",
      "[3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646, 3646]\n",
      "1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944 1944\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "300\n",
      "tensor(12.3421, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "the pacific islands nation of tuvalu was known by which name until becoming independent in 1974?\n",
      "y_del\n",
      "##encia cube thorne thorne hades hadesxious qualified qualified synthesized 255 cube hades hades hades hades hades premium陽\n",
      "y_ins\n",
      "the islands nationvalu was known by which until independent in 1974? [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 19, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1996,  3534,  3470,  3842,  1997, 10722, 10175,  2226,  2001,  2124,\n",
      "          2011,  2029,  2171,  2127,  3352,  2981,  1999,  3326,  1029]])\n",
      "torch.Size([1, 19])\n",
      "Decode step 1\n",
      "torch.Size([1, 19, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1996,  3797, 20637, 20637,  3534, 20637, 27483, 20637,  3470,  3842,\n",
      "          1997, 10722, 10175,  2226,  2001,  2124, 24550, 24550,  2011,  2029,\n",
      "          2171,  2127,  3352,  2981,  1999,  3326,  1029]])\n",
      "torch.Size([1, 27])\n",
      "Decode step 2\n",
      "[1996, 3797, 20637, 20637, 3534, 20637, 27483, 20637, 3470, 3842, 1997, 10722, 10175, 2226, 2001, 2124, 24550, 24550, 2011]\n",
      "the shirt 255 255 pacific 255ocating 255 islands nation of tuvalu was known celine celine by\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "350\n",
      "tensor(12.2603, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "for what offence was al capone jailed?\n",
      "y_del\n",
      "thorne thorne thorne [PAD] thorne recountsxious thorne [PAD]\n",
      "y_ins\n",
      "for what offence was capone jailed? [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 9, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2005,  2054, 15226,  2001,  2632,  6178,  5643, 21278,  1029]])\n",
      "torch.Size([1, 9])\n",
      "Decode step 1\n",
      "[2005, 2054, 15226, 2001, 2632, 6178, 5643, 21278, 1029]\n",
      "for what offence was al capone jailed?\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "400\n",
      "tensor(12.1442, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "how many mp's are there in the house of commons?\n",
      "y_del\n",
      "##onale performance supermarketuder mustache enable performance convergence apartheid supermarketjevic relation beaver\n",
      "y_ins\n",
      "how many mp's are there in the of commons? [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 13, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[2129, 2116, 6131, 1005, 1055, 2024, 2045, 1999, 1996, 2160, 1997, 7674,\n",
      "         1029]])\n",
      "torch.Size([1, 13])\n",
      "Decode step 1\n",
      "[2129, 2116, 6131, 1005, 1055, 2024, 2045, 1999, 1996, 2160, 1997, 7674, 1029]\n",
      "how many mp's are there in the house of commons?\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "450\n",
      "tensor(12.0557, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what was the name of the vlcc tanker that split in two off the coast of brittany in 1978?\n",
      "y_del\n",
      "influenza held [unused168] dusty pagan performanceolortaolo tablets performance 中 southward cardiovascular mustacheκ stilled hades bury hades advises exceptional\n",
      "y_ins\n",
      "was the name of the vlcc tanker that split two off the coast in? [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 22, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2054,  2001,  1996,  2171,  1997,  1996,  1058, 15472,  2278, 20135,\n",
      "          2008,  3975,  1999,  2048,  2125,  1996,  3023,  1997, 12686,  1999,\n",
      "          3301,  1029]])\n",
      "torch.Size([1, 22])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 1\n",
      "torch.Size([1, 22, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2054,  2001,  1996,  2171,  1997,  1996,  1058, 15472,  2278, 20135,\n",
      "          2008,  3975,  1999,  2048,  2125, 29549,  1996,  3023,  2218,  1997,\n",
      "         12686,  1999,  3301,  1029]])\n",
      "torch.Size([1, 24])\n",
      "Decode step 2\n",
      "torch.Size([1, 22, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[21709,  2054, 30499,  2001, 20968,  1996,  2171,  1997,  1996,  1058,\n",
      "         15472,  2278, 20135,  2008,  3975,  1999,  2048,  2125, 27742, 29549,\n",
      "          1996,  3023, 20968,  2218,  1997, 12686,  1999]])\n",
      "torch.Size([1, 27])\n",
      "Decode step 3\n",
      "[21709, 2054, 30499, 2001, 20968, 1996, 2171, 1997, 1996, 1058, 15472, 2278, 20135, 2008, 3975, 1999, 2048, 2125, 27742, 29549, 1996, 3023]\n",
      "##rot what陽 wasberries the name of the vlcc tanker that split in two offencia binoculars the coast\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "500\n",
      "tensor(11.9649, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "the musical play'over the rainbow'first shown in 2003 is a celebration of the life and music of which singer who died in 1996?\n",
      "y_del\n",
      "##stellarstellarstellarstellarstellarstellar rams 食pled synthesized rams [unused539] rams [PAD] loose 食 [unused168] 食 食 rams rams [PAD] hades [PAD] connie [PAD]stellar melancholy\n",
      "y_ins\n",
      "the play rainbow'first shown in is a celebration the music of which singer died in 1996? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 28, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 1996,  3315,  2377,  1005,  2058,  1996, 10098,  1005,  2034,  3491,\n",
      "          1999,  2494,  2003,  1037,  7401,  1997,  1996,  2166,  1998,  2189,\n",
      "          1997,  2029,  3220,  2040,  2351,  1999,  2727,  1029]])\n",
      "torch.Size([1, 28])\n",
      "Decode step 1\n",
      "[1996, 3315, 2377, 1005, 2058, 1996, 10098, 1005, 2034, 3491, 1999, 2494, 2003, 1037, 7401, 1997, 1996, 2166, 1998, 2189, 1997, 2029, 3220, 2040, 2351, 1999, 2727, 1029]\n",
      "the musical play'over the rainbow'first shown in 2003 is a celebration of the life and music of which singer who died in 1996?\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "550\n",
      "tensor(11.8564, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "the version of magna carta signed by king john of england at runnymede was annulled shortly afterwards by pope innocent iii ; who issued the version which then survived to become the basis of much of modern western law?\n",
      "y_del\n",
      "[PAD]aneousκե loose biographyaneous [PAD] reclamation trough troughhi [PAD] fjord symbolicene [PAD] 255eneา [unused986] [unused986] fifteen [unused986] exaggerated exaggerated float [PAD] [PAD] [PAD]κ concerto daly 255 255oman 255 [unused469] dalyե eternal [PAD]oman [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "version of magna carta signed by king england at runmede was annulled shortly afterwards by pope innocent iii ; issued the version then survived to become basis of much of modern? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 46, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1996,  2544,  1997, 20201, 11122,  2050,  2772,  2011,  2332,  2198,\n",
      "          1997,  2563,  2012,  2448,  4890,  7583,  2063,  2001,  5754, 18083,\n",
      "          2098,  3859,  5728,  2011,  4831,  7036,  3523,  1025,  2040,  3843,\n",
      "          1996,  2544,  2029,  2059,  5175,  2000,  2468,  1996,  3978,  1997,\n",
      "          2172,  1997,  2715,  2530,  2375,  1029]])\n",
      "torch.Size([1, 46])\n",
      "Decode step 1\n",
      "[1996, 2544, 1997, 20201, 11122, 2050, 2772, 2011, 2332, 2198, 1997, 2563, 2012, 2448, 4890, 7583, 2063, 2001, 5754, 18083, 2098, 3859, 5728, 2011, 4831, 7036, 3523, 1025, 2040, 3843, 1996, 2544, 2029, 2059, 5175, 2000, 2468, 1996, 3978, 1997, 2172, 1997, 2715, 2530, 2375, 1029]\n",
      "the version of magna carta signed by king john of england at runnymede was annulled shortly afterwards by pope innocent iii ; who issued the version which then survived to become the basis of much of modern western law?\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "600\n",
      "tensor(11.7469, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "in october 1992, which singer ripped up a photo of pope john paul ii on saturday night live, after performing a song protesting alleged child abuse by the catholic church?\n",
      "y_del\n",
      "thwarted [PAD] hades hades hades kerr hades hades hades 255 instrumental canned stimulated partition hades hades sheet [PAD] [PAD] hades hades [PAD] \" thwarted [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] psychiatric [PAD]\n",
      "y_ins\n",
      "in 1992, ripped up a photo of pope john paul ii on saturday night after performing a alleged abuse catholic church? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 33, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 1999,  2255,  2826,  1010,  2029,  3220,  9157,  2039,  1037,  6302,\n",
      "          1997,  4831,  2198,  2703,  2462,  2006,  5095,  2305,  2444,  1010,\n",
      "          2044,  4488,  1037,  2299, 21248,  6884,  2775,  6905,  2011,  1996,\n",
      "          3234,  2277,  1029]])\n",
      "torch.Size([1, 33])\n",
      "Decode step 1\n",
      "[1999, 2255, 2826, 1010, 2029, 3220, 9157, 2039, 1037, 6302, 1997, 4831, 2198, 2703, 2462, 2006, 5095, 2305, 2444, 1010, 2044, 4488, 1037, 2299, 21248, 6884, 2775, 6905, 2011, 1996, 3234, 2277, 1029]\n",
      "in october 1992, which singer ripped up a photo of pope john paul ii on saturday night live, after performing a song protesting alleged child abuse by the catholic church?\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "650\n",
      "tensor(11.7742, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "which large island lies off the coast of los angeles?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "which island lies off the coast los angeles? [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 11, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[2029, 2312, 2479, 3658, 2125, 1996, 3023, 1997, 3050, 3349, 1029]])\n",
      "torch.Size([1, 11])\n",
      "Decode step 1\n",
      "[2029, 2312, 2479, 3658, 2125, 1996, 3023, 1997, 3050, 3349, 1029]\n",
      "which large island lies off the coast of los angeles?\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "700\n",
      "tensor(11.6731, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "which engineer first used the term horsepower?\n",
      "y_del\n",
      "207 207 swarm thumb [unused168] thumbrot swarm\n",
      "y_ins\n",
      "which first used the term horsepower [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 8, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2029,  3992,  2034,  2109,  1996,  2744, 15149,  1029]])\n",
      "torch.Size([1, 8])\n",
      "Decode step 1\n",
      "[2029, 3992, 2034, 2109, 1996, 2744, 15149, 1029]\n",
      "which engineer first used the term horsepower?\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "750\n",
      "tensor(11.6540, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "\" \" \" now is the winter of our discontent \" \" is a line from which play? \"\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] rams [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "\" now the winter of our discontent \" \" line from play \" [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 20, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1000,  1000,  1000,  2085,  2003,  1996,  3467,  1997,  2256, 27648,\n",
      "          1000,  1000,  2003,  1037,  2240,  2013,  2029,  2377,  1029,  1000]])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 1\n",
      "[1000, 1000, 1000, 2085, 2003, 1996, 3467, 1997, 2256, 27648, 1000, 1000, 2003, 1037, 2240, 2013, 2029, 2377, 1029, 1000]\n",
      "\" \" \" now is the winter of our discontent \" \" is a line from which play? \"\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "800\n",
      "tensor(11.5725, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "' that's livin'alright'was the theme song to which tv programme?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "' that s livin'alright'was the theme song to tv programme? [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 18, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1005,  2008,  1005,  1055, 22135,  2378,  1005, 10303,  1005,  2001,\n",
      "          1996,  4323,  2299,  2000,  2029,  2694,  4746,  1029]])\n",
      "torch.Size([1, 18])\n",
      "Decode step 1\n",
      "[1005, 2008, 1005, 1055, 22135, 2378, 1005, 10303, 1005, 2001, 1996, 4323, 2299, 2000, 2029, 2694, 4746, 1029]\n",
      "' that's livin'alright'was the theme song to which tv programme?\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "850\n",
      "tensor(11.5350, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "in what year did germany officially reunify?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "in what year did officially refy? [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 10, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 1999,  2054,  2095,  2106,  2762,  3985,  2128, 19496, 12031,  1029]])\n",
      "torch.Size([1, 10])\n",
      "Decode step 1\n",
      "[1999, 2054, 2095, 2106, 2762, 3985, 2128, 19496, 12031, 1029]\n",
      "in what year did germany officially reunify?\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "900\n",
      "tensor(11.4875, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what is the maximum number of players in a rounders team?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "what is number of in a round team [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 13, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[2054, 2003, 1996, 4555, 2193, 1997, 2867, 1999, 1037, 2461, 2545, 2136,\n",
      "         1029]])\n",
      "torch.Size([1, 13])\n",
      "Decode step 1\n",
      "[2054, 2003, 1996, 4555, 2193, 1997, 2867, 1999, 1037, 2461, 2545, 2136, 1029]\n",
      "what is the maximum number of players in a rounders team?\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "950\n",
      "tensor(11.4181, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "according to the bible who was the mother of esau and jacob?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "the who was the of esau jacob? [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 14, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2429,  2000,  1996,  6331,  2040,  2001,  1996,  2388,  1997, 28776,\n",
      "          2226,  1998,  6213,  1029]])\n",
      "torch.Size([1, 14])\n",
      "Decode step 1\n",
      "[2429, 2000, 1996, 6331, 2040, 2001, 1996, 2388, 1997, 28776, 2226, 1998, 6213, 1029]\n",
      "according to the bible who was the mother of esau and jacob?\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1000\n",
      "tensor(11.3834, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "king albert ii abdicated as monarch of which country on july 21st 2013 in favour of his son crown prince phillipe?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "albert ii abdicated as monarch of which on july favour of his prince phillipe? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 24, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2332,  4789,  2462, 19935, 17872,  2004, 11590,  1997,  2029,  2406,\n",
      "          2006,  2251,  7398,  2286,  1999,  7927,  1997,  2010,  2365,  4410,\n",
      "          3159, 10852,  2063,  1029]])\n",
      "torch.Size([1, 24])\n",
      "Decode step 1\n",
      "[2332, 4789, 2462, 19935, 17872, 2004, 11590, 1997, 2029, 2406, 2006, 2251, 7398, 2286, 1999, 7927, 1997, 2010, 2365, 4410, 3159, 10852, 2063, 1029]\n",
      "king albert ii abdicated as monarch of which country on july 21st 2013 in favour of his son crown prince phillipe?\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1050\n",
      "tensor(11.3118, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what was the first name of the character played by george wendtin'cheers '?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "what the first name the character played by georgein'cheers '? [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 18, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2054,  2001,  1996,  2034,  2171,  1997,  1996,  2839,  2209,  2011,\n",
      "          2577, 19181, 11927,  2378,  1005, 21250,  1005,  1029]])\n",
      "torch.Size([1, 18])\n",
      "Decode step 1\n",
      "[2054, 2001, 1996, 2034, 2171, 1997, 1996, 2839, 2209, 2011, 2577, 19181, 11927, 2378, 1005, 21250, 1005, 1029]\n",
      "what was the first name of the character played by george wendtin'cheers '?\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1100\n",
      "tensor(11.3166, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "which disney cartoon character was originally known as dippy dawg?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "disney cartoon character was known dawg? [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 13, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2029,  6373,  9476,  2839,  2001,  2761,  2124,  2004, 16510,  7685,\n",
      "          4830, 27767,  1029]])\n",
      "torch.Size([1, 13])\n",
      "Decode step 1\n",
      "[2029, 6373, 9476, 2839, 2001, 2761, 2124, 2004, 16510, 7685, 4830, 27767, 1029]\n",
      "which disney cartoon character was originally known as dippy dawg?\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1150\n",
      "tensor(11.2738, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "the'puri / poori / puree'in the indian dish'prawn puri'refers to what aspect?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "pu / poori /e'the indian'praw pu'refers to what? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 27, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 1996,  1005, 16405,  3089,  1013,  3532,  2072,  1013,  5760,  2063,\n",
      "          1005,  1999,  1996,  2796,  9841,  1005, 10975, 10376,  2078, 16405,\n",
      "          3089,  1005,  5218,  2000,  2054,  7814,  1029]])\n",
      "torch.Size([1, 27])\n",
      "Decode step 1\n",
      "[1996, 1005, 16405, 3089, 1013, 3532, 2072, 1013, 5760, 2063, 1005, 1999, 1996, 2796, 9841, 1005, 10975, 10376, 2078, 16405, 3089, 1005, 5218, 2000, 2054, 7814, 1029]\n",
      "the'puri / poori / puree'in the indian dish'prawn puri'refers to what aspect?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1200\n",
      "tensor(11.2303, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "who led the first expedition to successfully circumnavigate the earth between 1519 and 1522, and was killed during the voyage?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "who first expedition successfully ciumnavigate the earth between 1519 1522, and was during the voyage [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 29, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2040,  2419,  1996,  2034,  5590,  2000,  5147, 25022, 11890,  2819,\n",
      "          2532,  5737,  5867,  1996,  3011,  2090, 16528,  2683,  1998, 15017,\n",
      "          2475,  1010,  1998,  2001,  2730,  2076,  1996,  8774,  1029]])\n",
      "torch.Size([1, 29])\n",
      "Decode step 1\n",
      "[2040, 2419, 1996, 2034, 5590, 2000, 5147, 25022, 11890, 2819, 2532, 5737, 5867, 1996, 3011, 2090, 16528, 2683, 1998, 15017, 2475, 1010, 1998, 2001, 2730, 2076, 1996, 8774, 1029]\n",
      "who led the first expedition to successfully circumnavigate the earth between 1519 and 1522, and was killed during the voyage?\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1250\n",
      "tensor(11.2062, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "which of the alkali metals, with the atomic number 19 is missing from - lithium, sodium, rubidium, caesium and francium?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "of the alkali metals, the atomic number is missing from - lithium, rubidium, caesium and francium? [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 31, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "tensor([[ 2029,  1997,  1996,  2632, 28613, 11970,  1010,  2007,  1996,  9593,\n",
      "          2193,  2539,  2003,  4394,  2013,  1011, 22157,  1010, 13365,  1010,\n",
      "         14548, 28742,  1010,  6187,  2229,  5007,  1998, 23151,  6895,  2819,\n",
      "          1029]])\n",
      "torch.Size([1, 31])\n",
      "Decode step 1\n",
      "[2029, 1997, 1996, 2632, 28613, 11970, 1010, 2007, 1996, 9593, 2193, 2539, 2003, 4394, 2013, 1011, 22157, 1010, 13365, 1010, 14548, 28742, 1010, 6187, 2229, 5007, 1998, 23151, 6895, 2819, 1029]\n",
      "which of the alkali metals, with the atomic number 19 is missing from - lithium, sodium, rubidium, caesium and francium?\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1300\n",
      "tensor(11.1819, grad_fn=<DivBackward0>)\n",
      "y_ground\n",
      "what is the name of the town that is host to it's a wonderful life?\n",
      "y_del\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "y_ins\n",
      "what the name of the town that is host it s a wonderful life? [PAD] [PAD] [PAD]\n",
      "Decode step 0\n",
      "torch.Size([1, 18, 2])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n",
      "tensor([[2054, 2003, 1996, 2171, 1997, 1996, 2237, 2008, 2003, 3677, 2000, 2009,\n",
      "         1005, 1055, 1037, 6919, 2166, 1029]])\n",
      "torch.Size([1, 18])\n",
      "Decode step 1\n",
      "[2054, 2003, 1996, 2171, 1997, 1996, 2237, 2008, 2003, 3677, 2000, 2009, 1005, 1055, 1037, 6919, 2166, 1029]\n",
      "what is the name of the town that is host to it's a wonderful life?\n"
     ]
    }
   ],
   "source": [
    "class DatasetSampler():\n",
    "    def __init__(self, tokenizer, encoder, alpha=0, beta=0, max_placeholders=2):\n",
    "        self.dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_placeholders = max_placeholders\n",
    "            \n",
    "    def encode_and_pad(self, string, pad_length):\n",
    "        string = self.tokenizer.encode(string)\n",
    "        while len(string) < pad_length:\n",
    "            string.append(self.tokenizer.pad_token_id)\n",
    "        return torch.LongTensor([string])\n",
    "    \n",
    "    '''\n",
    "        Encode the passed strings and pad to the specified length\n",
    "    '''\n",
    "    def encode_and_pad_batch(self, strings):\n",
    "        encoded = [self.tokenizer.encode(s) for s in strings]\n",
    "        pad_length = max([len(s) for s in encoded])\n",
    "        padded = torch.zeros(len(strings), pad_length, dtype=torch.int64) # because self.tokenizer.pad_token_id == 0\n",
    "        for i in range(len(encoded)):\n",
    "            for j in range(len(encoded[i])):\n",
    "                padded[i,j] = encoded[i][j]\n",
    "        return padded\n",
    "        \n",
    "    def sample(self, bs=10, pad_to=30, t_classifier=None):\n",
    "        '''Sample an observation and return tensor tuples:\n",
    "        1) (a) the observation perturbed with deletions, for input to the placeholder classifier\n",
    "           (b) the indices of the deleted tokens (i.e. where placeholders should be inserted, for the placeholder classifier loss) \n",
    "        2) (a) 1(a), but with PLH replacing each deleted token. For input to the token insertion classifier \n",
    "           (b) the number of placeholders tokens to insert at each index in 1(a) (for the placeholder classifier loss)\n",
    "        3) (a) the observation perturbed with insertion (tokens), for input to the token deletion classifier \n",
    "           (b) 2(a) (for the token insertion classifier loss)\n",
    "        '''\n",
    "        u = random.random()\n",
    "        v = random.random()\n",
    "        # sample a pair of (untokenized) strings \n",
    "        y_ground = [self.dataset.sample() for i in range(bs)]\n",
    "        y0 = []\n",
    "        \n",
    "        # first, pad/encode y0 and y_ground\n",
    "        y_ground = [self.tokenizer.encode(s) for s in y_ground]\n",
    "        \n",
    "        # randomly choose between LD-minimal deletion and random deletion\n",
    "        # Returns tensors of:\n",
    "        # - the token sequence post-deletion\n",
    "        # - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "        # - whether a given index was deleted or not\n",
    "        if len(y0) == 0:\n",
    "            y_ins, y_ins_with_placeholders, y_ins_p = delete_random(y_ground)\n",
    "        elif u >= self.alpha:\n",
    "            y_ins, y_ins_with_placeholders, y_ins_p = delete_random(y0)\n",
    "        else:\n",
    "            y_ins, y_ins_with_placeholders, y_ins_p = delete_minimal(y0, y_ground)\n",
    "\n",
    "        # Returns tensors of:\n",
    "        # - (1, n+1) - the number of PLH tags at each index\n",
    "        # - (1, k) - the inserted tokens\n",
    "        # - (1, n+k) - the entire post-insertion sequence\n",
    "        # where n is the length of the original sequence and k is the number of tokens added \n",
    "        y_placeholders, y_inserted, y_ins_prime = insert_minimal(y_ins, y_ground, self.max_placeholders)\n",
    "\n",
    "        # input to the deletion classifier will be randomly chosen between:\n",
    "        # - the input to the placeholder classifier (i.e. the deleted input)\n",
    "        # - the output from applying the token classifier to y_placeholders\n",
    "        if v >= self.alpha and len(y0) != 0:\n",
    "            y_del = y_ins\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                enc = self.encoder(torch.LongTensor(pad(y_ins_with_placeholders, pad_token=0)))[0]\n",
    "                logits = t_classifier(enc)\n",
    "                y_del = torch.argmax(logits,dim=2)\n",
    "                y_del = torch.LongTensor(y_del)\n",
    "                \n",
    "        y_ins_pad_len = max(max([len(i) for i in y_placeholders]), max([len(i) for i in y_ins]), max([len(i) for i in y_ins_prime]))\n",
    "        y_ins = torch.LongTensor(pad(y_ins, pad_len=y_ins_pad_len))\n",
    "        y_placeholders = torch.LongTensor(pad(y_placeholders, pad_len=y_ins_pad_len))\n",
    "        \n",
    "        y_ins_p = torch.LongTensor(pad(y_ins_p, pad_token=0))\n",
    "        \n",
    "        y_del = torch.LongTensor(pad(y_del, pad_len=y_ins_p.size(1), pad_token=0))\n",
    "        \n",
    "        y_ins_prime = torch.LongTensor(pad(y_ins_prime, pad_token=0, pad_len=y_ins_pad_len))\n",
    "        \n",
    "        #print(\"y_placeholders\")\n",
    "        #print(y_placeholders.size())\n",
    "        #print(\"y_ins_prim\")\n",
    "        #print(y_ins_prime.size())\n",
    "        #print(\"y_ins\")\n",
    "        #print(y_ins.size())\n",
    "        \n",
    "        assert y_ins_prime.size(1) == y_ins.size(1)\n",
    "        \n",
    "        return ((y_del, self.encoder(y_del)[0], y_ins_p), \n",
    "               (y_ins, self.encoder(y_ins)[0], y_placeholders), \n",
    "               (y_ins_prime, self.encoder(y_ins_prime)[0], y_ins), y_ground)\n",
    "                \n",
    "class Model():\n",
    "    def __init__(self, sampler, vocab_size, hsz=768, lr=0.0001):\n",
    "        super().__init__()\n",
    "        self.sampler = sampler\n",
    "        self.p_classifier = PlaceholderClassifier(hsz, max_placeholders=sampler.max_placeholders)\n",
    "        self.t_classifier = TokenClassifier(hsz, vocab_size, 20)\n",
    "        self.d_classifier = DeletionClassifier(hsz)        \n",
    "        self.alpha = 0.5\n",
    "        self.beta = 0.5\n",
    "        self.p_loss = nn.CrossEntropyLoss()\n",
    "        self.t_loss = nn.CrossEntropyLoss()\n",
    "        self.d_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optims = {\n",
    "            'p_classifier': optim.SGD(self.p_classifier.parameters(), lr=lr),\n",
    "            't_classifier': optim.SGD(self.t_classifier.parameters(), lr=lr),\n",
    "            'd_classifier': optim.SGD(self.d_classifier.parameters(), lr=lr),\n",
    "        }\n",
    "        \n",
    "        self.step = 0\n",
    "        self.loss = 0\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "    def decode_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.p_classifier.eval()\n",
    "            self.t_classifier.eval()\n",
    "            self.d_classifier.eval()\n",
    "\n",
    "            (y_del,y_del_enc,_), (y_ins,_,_), (y_ins_prime, _,_), y_ground = self.sampler.sample(bs=1, t_classifier=self.t_classifier)\n",
    "            print(\"y_ground\")\n",
    "            print(tokenizer.decode(y_ground[0]))\n",
    "            print(\"y_del\")\n",
    "            print(tokenizer.decode(y_del[0].tolist()))\n",
    "            print(\"y_ins\")\n",
    "            print(tokenizer.decode(y_ins[0].tolist()))\n",
    "\n",
    "            y_ground = y_ins_prime\n",
    "            y_last = None\n",
    "\n",
    "            step = 0\n",
    "            max_steps = 10\n",
    "\n",
    "            while True:\n",
    "                print(\"Decode step %d\" % step)\n",
    "                step += 1\n",
    "                if step > max_steps:\n",
    "                    y_ground = y_last\n",
    "                    break\n",
    "                if y_last is not None:\n",
    "                    if (y_last.size() == y_ground.size() and torch.all(y_last == y_ground)):\n",
    "                        break         \n",
    "                    y_ground = y_last\n",
    "                \n",
    "                # deletion first\n",
    "                preds_deletes = self.d_classifier(y_del_enc).cuda()\n",
    "                if preds_deletes.size(1) == 0:\n",
    "                    continue\n",
    "\n",
    "                deletions = torch.argmax(preds_deletes,2)\n",
    "                \n",
    "                deleted = [y_ground[0,i].item() for i in range(deletions.size(1)) if deletions[0,i] == 0]\n",
    "\n",
    "                y_ground = tokenizer.decode(deleted)\n",
    "\n",
    "                # then placeholder\n",
    "                y_ground = encoder(torch.LongTensor([deleted]))[0]\n",
    "\n",
    "                preds_placeholders = self.p_classifier(y_ground).cuda()\n",
    "                if preds_placeholders.size(1) == 0:\n",
    "                    y_ground = torch.LongTensor([deleted])\n",
    "                    continue\n",
    "                placeholders = torch.argmax(preds_placeholders,2)\n",
    "\n",
    "                reconstructed = []\n",
    "                for i in range(placeholders.size(1)):\n",
    "                    for j in range(placeholders[0,i].item()):\n",
    "                        reconstructed.append(plh)\n",
    "                    reconstructed.append(deleted[i])\n",
    "\n",
    "                y_ground = torch.LongTensor([reconstructed])\n",
    "\n",
    "                # then inserts\n",
    "                inserts = self.t_classifier(encoder(torch.LongTensor([reconstructed]))[0]).cuda()\n",
    "                inserts = torch.argmax(inserts, 2)\n",
    "                j = 0\n",
    "\n",
    "                for i in range(len(reconstructed)):\n",
    "                    if reconstructed[i] == plh:\n",
    "                        if i < len(reconstructed):\n",
    "                            reconstructed[i] = inserts[0,j].item()\n",
    "                        else:\n",
    "                            reconstructed.append(inserts[0,j].item())\n",
    "                        j += 1\n",
    "\n",
    "                y_last = torch.LongTensor([reconstructed])\n",
    "            if y_last is not None:\n",
    "                print(y_last[0].tolist())\n",
    "                print(tokenizer.decode(y_last[0].tolist()))\n",
    "            else:\n",
    "                print(\"y_last none\")\n",
    "            \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.p_classifier.train()\n",
    "        self.t_classifier.train()\n",
    "        self.d_classifier.train()\n",
    "        \n",
    "        (y_del,y_del_enc,y_del_out), (y_ins,y_ins_enc,y_ins_out), (y_ins_prime, y_ins_prime_enc, y_ins_prime_out), _ = self.sampler.sample(bs=1, t_classifier=self.t_classifier)\n",
    "        \n",
    "        preds_deletes = self.d_classifier(y_del_enc)\n",
    "        preds_placeholders = self.p_classifier(y_ins_enc)\n",
    "        preds_inserts = self.t_classifier(y_ins_prime_enc)\n",
    "        \n",
    "        loss = self.d_loss(torch.transpose(preds_deletes, 1, 2), y_del_out)\n",
    "        loss += self.p_loss(torch.transpose(preds_placeholders, 1, 2), y_ins_out)\n",
    "        loss += self.t_loss(torch.transpose(preds_inserts,1,2), y_ins_prime_out)\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % 10 == 0:\n",
    "            print(self.step)\n",
    "        if self.step % 50 == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.decode_step()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "sampler = DatasetSampler(tokenizer, encoder, max_placeholders=5)\n",
    "\n",
    "model = Model(sampler, len(tokenizer))\n",
    "for i in range(10000):\n",
    "    model.train_step()\n",
    "#model.decode_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode step 0\n",
      "tensor([[0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "post deleted\n",
      "i are go to the mall\n",
      "Decode step 1\n",
      "[1045, 2024, 2175, 2000, 1996, 6670]\n",
      "i are go to the mall\n",
      "Decode step 0\n",
      "tensor([[0, 0, 0, 0]], device='cuda:0')\n",
      "post deleted\n",
      "she am my mother\n",
      "Decode step 1\n",
      "[2016, 2572, 2026, 2388]\n",
      "she am my mother\n"
     ]
    }
   ],
   "source": [
    "def decode(self, text):\n",
    "        \n",
    "    self.p_classifier.eval()\n",
    "    self.t_classifier.eval()\n",
    "    self.d_classifier.eval()\n",
    "\n",
    "    step = 0\n",
    "    max_steps = 10\n",
    "    \n",
    "    y_last = None\n",
    "    y_ground = torch.LongTensor([tokenizer.encode(text)])\n",
    "    y_ground_enc = encoder(y_ground)[0]\n",
    "    \n",
    "    while True:\n",
    "        print(\"Decode step %d\" % step)\n",
    "        step += 1\n",
    "        if step > max_steps:\n",
    "            y_ground = y_last\n",
    "            break\n",
    "        if y_last is not None:\n",
    "            if (y_last.size() == y_ground.size() and torch.all(y_last == y_ground)):\n",
    "                break         \n",
    "            y_ground = y_last\n",
    "                \n",
    "        # deletion first\n",
    "        preds_deletes = self.d_classifier(y_ground_enc).cuda()\n",
    "        if preds_deletes.size(1) == 0:\n",
    "            continue\n",
    "\n",
    "        deletions = torch.argmax(preds_deletes,2)\n",
    "        print(deletions)\n",
    "\n",
    "        deleted = [y_ground[0,i].item() for i in range(deletions.size(1)) if deletions[0,i] == 0]\n",
    "\n",
    "        y_ground = tokenizer.decode(deleted)\n",
    "        print(\"post deleted\")\n",
    "        print(y_ground)\n",
    "\n",
    "        # then placeholder\n",
    "        y_ground = encoder(torch.LongTensor([deleted]))[0]\n",
    "\n",
    "        preds_placeholders = self.p_classifier(y_ground).cuda()\n",
    "        if preds_placeholders.size(1) == 0:\n",
    "            y_ground = torch.LongTensor([deleted])\n",
    "            continue\n",
    "        placeholders = torch.argmax(preds_placeholders,2)\n",
    "\n",
    "        reconstructed = []\n",
    "        for i in range(placeholders.size(1)):\n",
    "            for j in range(placeholders[0,i].item()):\n",
    "                reconstructed.append(plh)\n",
    "            reconstructed.append(deleted[i])\n",
    "\n",
    "        y_ground = torch.LongTensor([reconstructed])\n",
    "\n",
    "        # then inserts\n",
    "        inserts = self.t_classifier(encoder(torch.LongTensor([reconstructed]))[0]).cuda()\n",
    "        inserts = torch.argmax(inserts, 2)\n",
    "        j = 0\n",
    "\n",
    "        for i in range(len(reconstructed)):\n",
    "            if reconstructed[i] == plh:\n",
    "                if i < len(reconstructed):\n",
    "                    reconstructed[i] = inserts[0,j].item()\n",
    "                else:\n",
    "                    reconstructed.append(inserts[0,j].item())\n",
    "                j += 1\n",
    "\n",
    "        y_last = torch.LongTensor([reconstructed])\n",
    "    if y_last is not None:\n",
    "        print(y_last[0].tolist())\n",
    "        print(tokenizer.decode(y_last[0].tolist()))\n",
    "    else:\n",
    "        print(\"y_last none\")\n",
    "decode(model, \"I are go to the mall\")\n",
    "decode(model, \"She am my mother\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
