{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn.modules.transformer import Transformer, TransformerEncoder, TransformerEncoderLayer\n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from torch import nn\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<PLH>', '<s>','</s>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "#encoder = DistilBertModel.from_pretrained('distilbert-base-uncased').cuda()\n",
    "#encoder.resize_token_embeddings(len(tokenizer))  \n",
    "\n",
    "noop = \"N\"\n",
    "sub = \"S\"\n",
    "insert = \"I\"\n",
    "delete = \"D\"\n",
    "\n",
    "def ld(s1, s2, subcost=1, delcost=1, inscost=1):\n",
    "    operations = [[\"\" for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n",
    "    \n",
    "    matrix = np.zeros((len(s1)+1, len(s2)+1))\n",
    "    \n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0,j] = j\n",
    "        operations[0][j] = insert\n",
    "        for i in range(len(s1) + 1):\n",
    "            matrix[i,0] = i\n",
    "            operations[i][0] = insert\n",
    "            if i > 0 and j > 0:\n",
    "                subCost = matrix[i-1, j-1] if s1[i-1] == s2[j-1] else matrix[i-1, j-1] + subcost\n",
    "                insertCost = matrix[i, j-1] + inscost\n",
    "                deleteCost = matrix[i-1, j] + delcost\n",
    "                minCost = min(subCost, insertCost, deleteCost)\n",
    "                matrix[i,j] = minCost\n",
    "                if minCost == 0:\n",
    "                    operations[i][j] = noop\n",
    "                elif minCost == deleteCost:\n",
    "                    operations[i][j] = delete\n",
    "                elif minCost == insertCost:\n",
    "                    operations[i][j] = insert\n",
    "                elif minCost == subCost:\n",
    "                    operations[i][j] = sub\n",
    "    i = len(s1)\n",
    "    j = len(s2)\n",
    "    history = []\n",
    "    while j > 0 or i > 0:        \n",
    "        if delcost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i-1,j]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "        elif inscost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i,j-1]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append((insert,s2[j-1]))\n",
    "                #history.append(insert)\n",
    "                j -= 1\n",
    "    history.reverse()\n",
    "    return matrix, matrix[len(s1),len(s2)], history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Which English town shares its name with the state capital of Delaware? </s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, \"r\") as infile:\n",
    "            self.data = json.load(infile)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"Data\"])\n",
    "\n",
    "    def sample(self):\n",
    "        key = \"Question\" if random.random() > 0.5 else \"Answer\"\n",
    "        return \"<s> \" + self.data[\"Data\"][random.randint(0, len(self.data[\"Data\"]) - 1)][\"Question\"] + \" </s>\"\n",
    "    \n",
    "plh = tokenizer.encode(\"<PLH>\")[0]\n",
    "ts = tokenizer.encode(\"<s>\")[0]\n",
    "te = tokenizer.encode(\"</s>\")[0]\n",
    "\n",
    "class PlaceholderClassifier(nn.Module):\n",
    "    def __init__(self, hsz, transformer, max_placeholders=2):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(\n",
    "            hsz*2,max_placeholders\n",
    "        )\n",
    "        self.hsz = hsz\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        transformed = self.transformer(input)\n",
    "        concatenated = torch.cat([transformed[:, :-1, :], transformed[:, 1:, :]], 2)\n",
    "        return self.dense(concatenated)\n",
    "    \n",
    "class TokenClassifier(nn.Module):    \n",
    "    def __init__(self, hsz, embedding, transformer, vsz, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.dense = nn.Linear(\n",
    "            hsz,vsz\n",
    "        )\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        hidden = self.transformer(self.embedding(input))\n",
    "        return torch.matmul(hidden, self.dense.weight.transpose(0,1).unsqueeze(0))\n",
    "        \n",
    "class DeletionClassifier(nn.Module):    \n",
    "    def __init__(self, hsz, transformer):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(\n",
    "            hsz, 2,\n",
    "        )\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.dense(self.transformer(input))\n",
    "\n",
    "class TransformerEncoderLayers(nn.Module):\n",
    "    def __init__(self, vsz, hsz,num_heads=8, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = TransformerEncoder(TransformerEncoderLayer(hsz, num_heads), num_layers)\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.transformer(input)\n",
    "    \n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vsz, hsz):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vsz, hsz,\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.embedding(input)\n",
    "    \n",
    "dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(items, pad_len=10, pad_token=0, pad_dim=1):\n",
    "    \"\"\"Pads the items to the specified length. \n",
    "    Also returns a binary padding mask (1/0 indicating non-padded/padded tokens respectively)\"\"\"\n",
    "    if type(items) == list:\n",
    "        if pad_len == 0:\n",
    "            pad_len = max([len(i) for i in items])\n",
    "        mask = torch.ones((len(items), pad_len), dtype=torch.long)\n",
    "        copy = items.copy()\n",
    "        for i in range(len(copy)):\n",
    "            mask[i,len(copy[i]):] = 0\n",
    "            copy[i] += [pad_token] * (pad_len - len(copy[i]))\n",
    "        return copy, mask\n",
    "    else:\n",
    "        copy = torch.zeros((items.size(0),pad_len), dtype=items.dtype)\n",
    "        copy[:,:items.size(1)] = items\n",
    "        mask = copy != pad_token\n",
    "        return copy, mask.long()\n",
    "    \n",
    "def apply_deletion(source, deletions):\n",
    "    def apply():\n",
    "        yield ts\n",
    "        for i in range(1, len(source) - 1):\n",
    "            if deletions[i] == 0:\n",
    "                yield source[i].item()  \n",
    "        yield te\n",
    "    return list(apply())\n",
    "\n",
    "def placeholders_from_mask(source, placeholder_mask, strip_tags=False, max_seq_len=50):\n",
    "    if type(source) == list:\n",
    "            source = torch.LongTensor(source)\n",
    "    if type(placeholder_mask) == list:\n",
    "        placeholder_mask = torch.LongTensor(placeholder_mask)\n",
    "    \n",
    "    def generate():\n",
    "        yield ts\n",
    "        yielded = 1\n",
    "        for i in range(1, placeholder_mask.size(0)):\n",
    "            if yielded >= max_seq_len:\n",
    "                break\n",
    "            if source[i].item() == te:\n",
    "                placeholder_mask[i] = 0\n",
    "                yield te\n",
    "            else:\n",
    "                if placeholder_mask[i] == 1:\n",
    "                    yield plh\n",
    "                    yielded += 1\n",
    "                yield source[i].item()\n",
    "                yielded += 1\n",
    "    placeholders= list(generate())\n",
    "    deletion_mask = [1 if p == plh else 0 for p in placeholders]\n",
    "    return torch.LongTensor(placeholders), torch.LongTensor(deletion_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InsertionInput():\n",
    "    '''\n",
    "    Wraps tensors of;\n",
    "    - the original sequence\n",
    "    - the post-deletion sequence\n",
    "    - the post-deletion sequence (including placeholders)\n",
    "    - boolean indicating whether the tokens at index i was deleted\n",
    "    '''\n",
    "    def __init__(self, ground, max_placeholders=2, p_del=0.1,pad_len=50):\n",
    "        ground, self.ground_pad_mask = pad(ground, pad_len=max([len(x) for x in ground]))\n",
    "        self.ground = torch.cuda.LongTensor(ground)\n",
    "        self.p_del = p_del\n",
    "        self.max_placeholders = max_placeholders\n",
    "        self.pad_len = pad_len\n",
    "        self.delete_random()\n",
    "        \n",
    "    def delete_random(self):\n",
    "        \"\"\"Deletes token(s) randomly from the passed (tokenized) string with probability p\n",
    "        Accepts:\n",
    "        - a list of token sequences bsz * pad_length\n",
    "        Returns tensors of:\n",
    "        - the token sequence post-deletion\n",
    "        - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "        - the number of placeholders inserted at each post-deletion index\n",
    "        \"\"\"\n",
    "        deletion_mask = torch.cuda.FloatTensor(self.ground.size()).uniform_() > (1 - self.p_del)\n",
    "        \n",
    "        # don't delete <s> or </s> tags\n",
    "        deletion_mask[self.ground == ts] = False\n",
    "        deletion_mask[self.ground == te] = False\n",
    "        self.deleted = self.ground.clone() * (deletion_mask == False).long()\n",
    "        if self.deleted.size(1) > self.pad_len:\n",
    "            self.deleted = self.deleted[:,:self.pad_len]\n",
    "        else:\n",
    "            self.deleted, self.deleted_mask = pad(self.deleted, pad_len=self.pad_len)\n",
    "        \n",
    "        self.placeholders = self.ground.clone()\n",
    "        \n",
    "        self.placeholders[deletion_mask == 1] = plh\n",
    "        \n",
    "        # sum every adjacent deletion to get the total number of placeholders to be inserted at that position\n",
    "        def get_placeholders(batch_idx):\n",
    "            accum = 0\n",
    "            for i in range(1, deletion_mask.size(1)): # start at 1 to skip <s> tag\n",
    "                if deletion_mask[batch_idx,i] == 1:\n",
    "                    accum += 1\n",
    "                else:\n",
    "                    if accum > 0:\n",
    "                        yield min(accum, self.max_placeholders - 1)\n",
    "                    yield 0\n",
    "                    accum = 0\n",
    "            if accum > 0:\n",
    "                yield min(accum, self.max_placeholders - 1)\n",
    "        \n",
    "        self.num_placeholders = [list(get_placeholders(i)) for i in range(self.ground.size(0))]\n",
    "        self.num_placeholders, self.num_placeholders_mask = pad(self.num_placeholders, pad_len=self.deleted.size(1) - 1)\n",
    "        self.num_placeholders = torch.LongTensor(self.num_placeholders)\n",
    "\n",
    "        # trim if we've exceeded the maximum number of placeholders to insert\n",
    "        if self.num_placeholders.size(1) != self.deleted.size(1) - 1:\n",
    "            self.num_placeholders = self.num_placeholders[:,self.deleted.size(1) - 1]\n",
    "\n",
    "class DeletionInput():\n",
    "    \"\"\"Randomly inserts tokens into the sequence\n",
    "    Wraps tensors of:\n",
    "    - the post-insertion sequence\n",
    "    - the indices of the inserted tokens\n",
    "    \"\"\" \n",
    "    def __init__(self, insertion_input, t_classifier, p_ins=0.1, max_inserts=5, pad_len=50):\n",
    "        # binary tensor indicating which tokens will be deleted (-1 for padded locations)\n",
    "        self.to_delete = torch.cuda.FloatTensor(seq_len).uniform_() > (1 - p_ins)\n",
    "        \n",
    "        torch.full((insertion_input.ground.size(0),pad_len),-1,dtype=torch.long)\n",
    "        \n",
    "        with_placeholders = torch.full((insertion_input.ground.size(0),pad_len),-1, dtype=torch.long)\n",
    "        \n",
    "        # generate placeholder/deletion mask for each sample\n",
    "        for batch_idx in range(insertion_input.ground.size(0)):\n",
    "            seq_len = insertion_input.ground[batch_idx].size(0)\n",
    "            placeholder_mask = torch.cuda.FloatTensor(seq_len).uniform_() > (1 - p_ins)\n",
    "            placeholder_mask = placeholder_mask.long()\n",
    "            placeholders, deletion_mask = placeholders_from_mask(insertion_input.ground[batch_idx], placeholder_mask)\n",
    "            with_placeholders[batch_idx,:placeholders.size(0)] = placeholders\n",
    "            self.to_delete[batch_idx, :len(deletion_mask)] = deletion_mask\n",
    "        \n",
    "        # replace all PLH tokens with tokens from the insertion classifier\n",
    "        insert_tokens = t_classifier(with_placeholders.cuda())\n",
    "        \n",
    "        insert_tokens = torch.argmax(insert_tokens,dim=2)\n",
    "\n",
    "        self.with_tokens = with_placeholders.clone()\n",
    "        \n",
    "        for batch_idx in range(insertion_input.ground.size(0)):\n",
    "            for i in range(insert_tokens.size(1)):\n",
    "                if self.with_tokens[batch_idx,i] == te:\n",
    "                    break\n",
    "                    \n",
    "                if self.with_tokens[batch_idx,i] == plh:\n",
    "                    self.with_tokens[batch_idx,i] = insert_tokens[batch_idx,i]\n",
    "        \n",
    "        if insertion_input.ground.size(1) < pad_len:\n",
    "            self.ground_padded, self.ground_padded_mask = pad(insertion_input.ground,pad_len=pad_len)\n",
    "        else:\n",
    "            print(tokenizer.decode(insertion_input.ground))\n",
    "            self.ground_padded = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, vocab_size, hsz=768, lr=0.001, max_placeholders=3, alpha=0, beta=0, pad_len=100):\n",
    "        super().__init__()\n",
    "        self.pad_len = pad_len\n",
    "        self.transformer = TransformerEncoderLayers(len(tokenizer), hsz)\n",
    "        self.p_classifier = PlaceholderClassifier(hsz, self.transformer).cuda()\n",
    "        self.embedder = Embedding(vocab_size,hsz)\n",
    "        self.t_classifier = TokenClassifier(hsz, self.embedder, self.transformer, vocab_size, 20).cuda()\n",
    "        self.d_classifier = DeletionClassifier(hsz, self.transformer).cuda()\n",
    "        \n",
    "        self.dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_placeholders = max_placeholders             \n",
    "        \n",
    "        self.alpha = 0.5\n",
    "        self.beta = 0.5\n",
    "        self.p_loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        self.t_loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        self.d_loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.optims = {\n",
    "            'p_classifier': optim.Adam(self.p_classifier.parameters(), lr=lr),\n",
    "            't_classifier': optim.Adam(self.t_classifier.parameters(), lr=lr),\n",
    "            'd_classifier': optim.Adam(self.d_classifier.parameters(), lr=lr),\n",
    "        }\n",
    "        \n",
    "        self.step = 0\n",
    "        self.loss = 0\n",
    "                        \n",
    "    def sample(self, bs=10, max_samples=30):\n",
    "        '''Sample an observation and return tensor tuples:\n",
    "        \n",
    "        2) (a) 1(a), but with PLH replacing each deleted token. For input to the token insertion classifier \n",
    "           (b) the number of placeholders tokens to insert at each index in 1(a) (for the placeholder classifier loss)\n",
    "        3) (a) the observation perturbed with insertion (tokens), for input to the token deletion classifier \n",
    "           (b) 2(a) (for the token insertion classifier loss)\n",
    "        '''\n",
    "        \n",
    "        v = random.random()\n",
    "        \n",
    "        # sample an untokenized string\n",
    "        ground = [self.dataset.sample() for i in range(bs)]\n",
    "        # tokenize/encode\n",
    "        encoded = [self.tokenizer.encode(s) for s in ground]\n",
    "        \n",
    "        deletion_input = None\n",
    "        drawn = 0\n",
    "        while deletion_input is None or deletion_input.ground_padded is None:\n",
    "            if drawn > max_samples:\n",
    "                raise Exception(\"Reached max number of sample iterations without a valid sample\")\n",
    "            drawn += 1\n",
    "            insertion_input = InsertionInput(encoded, pad_len=self.pad_len)\n",
    "            deletion_input = DeletionInput(insertion_input, self.t_classifier, pad_len=self.pad_len)\n",
    "    \n",
    "        return insertion_input, deletion_input\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "    def encode_list(self, tokens):\n",
    "        if type(tokens) == list:\n",
    "            return encoder(torch.LongTensor([tokens]).cuda())[0]\n",
    "        return encoder(tokens)[0]\n",
    "            \n",
    "    def pretty_print(self, label, tokens):\n",
    "        if type(tokens) == torch.Tensor:\n",
    "            tokens = tokens.tolist()\n",
    "        pretty = \"%s \\n %s\" % (label, tokenizer.decode(tokens))\n",
    "        pretty = pretty.replace(\"[PAD]\",\"\")\n",
    "        print(pretty)\n",
    "        \n",
    "    def decode_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.p_classifier.eval()\n",
    "            self.t_classifier.eval()\n",
    "            self.d_classifier.eval()\n",
    "\n",
    "            insertion_input, deletion_input = self.sample(bs=10)\n",
    "            #self.pretty_print(\"Ground truth\", insertion_input.ground[0])\n",
    "            #self.pretty_print(\"Ground truth post-deletion\", insertion_input.deleted[0].tolist())\n",
    "\n",
    "            step = 0\n",
    "            max_steps = 5\n",
    "            last = insertion_input.deleted\n",
    "            ground = last\n",
    "            \n",
    "            while True:            \n",
    "                self.pretty_print(\"Last\", last[0])\n",
    "                if step > max_steps:\n",
    "                    ground = last\n",
    "                    break\n",
    "                \n",
    "                if step > 0 and (last.size() == ground.size() and torch.all(last == ground)):\n",
    "                    break\n",
    "                \n",
    "                print(\"Decode step %d\" % step)\n",
    "                \n",
    "                step += 1    \n",
    "                \n",
    "                # run a deletion pass\n",
    "                preds_deletes = self.d_classifier(self.embedder(ground.cuda()))\n",
    "                if preds_deletes.size(1) > 0:\n",
    "                    deletions = torch.argmax(preds_deletes,2)\n",
    "                    assert ground.size(1) >= deletions.size(1)\n",
    "                    deleted = [ts]\n",
    "                    for i in range(1, deletions.size(1) - 1):\n",
    "                        if deletions[0,i] == 0:\n",
    "                            deleted.append(ground[0,i].item())\n",
    "                    deleted.append(te)\n",
    "                    ground = torch.LongTensor([deleted])\n",
    "                    self.pretty_print(\"Post-deletion\", deleted)\n",
    "                else:\n",
    "                    print(\"No deletions\")\n",
    "                \n",
    "                preds_placeholders = self.p_classifier(self.embedder(ground.cuda()).cuda())\n",
    "                # then run a placeholder pass                    \n",
    "                if preds_placeholders.size(1) == 0:\n",
    "                    print(\"No placeholders\")\n",
    "                    continue\n",
    "                    \n",
    "                #print(\"preds_placeholders\")                \n",
    "                #print(preds_placeholders.size())                \n",
    "                placeholders = torch.argmax(preds_placeholders,2)\n",
    "                #print(\"ground\")\n",
    "                #print(ground.size())\n",
    "                #print(\"first\")\n",
    "                #print(ground[0,0].item())\n",
    "                #print(\"placeholders:\")\n",
    "                #print(placeholders)\n",
    "                \n",
    "                reconstructed = [ts]\n",
    "                for i in range(1, ground.size(1) - 1): # skip first (<s>) and last (</s>) tokens \n",
    "                    for j in range(placeholders[0,i].item()):\n",
    "                        if len(reconstructed) < 512:\n",
    "                            reconstructed.append(plh)\n",
    "                    if len(reconstructed) < 512:\n",
    "                        item = ground[0,i].item()\n",
    "                        reconstructed.append(item)\n",
    "                        if item == te:\n",
    "                            break\n",
    "                if reconstructed[-1] != te:\n",
    "                    reconstructed.append(te)\n",
    "                    \n",
    "                self.pretty_print(\"Post-placeholders\", reconstructed)\n",
    "                      \n",
    "                # then an insertion pass\n",
    "                preds_inserts = self.t_classifier(torch.cuda.LongTensor([reconstructed]))\n",
    "                inserts = torch.argmax(preds_inserts, 2)\n",
    "                #print(\"inserts\")\n",
    "                #print(inserts)\n",
    "                \n",
    "                output = [reconstructed[0]]\n",
    "                for i in range(1,len(reconstructed) - 1):\n",
    "                    if reconstructed[i] == plh:\n",
    "                        output.append(inserts[0,i].item())\n",
    "                    else:\n",
    "                        output.append(reconstructed[i])\n",
    "                output.append(reconstructed[-1])\n",
    "                self.pretty_print(\"Post-insert\", output)\n",
    "                last = torch.LongTensor([output])\n",
    "            if last is not None:\n",
    "                #print(last[0].tolist())\n",
    "                print(tokenizer.decode(last[0].tolist()))\n",
    "            else:\n",
    "                print(\"Couldn't decode\")\n",
    "            \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.p_classifier.train()\n",
    "        self.t_classifier.train()\n",
    "        self.d_classifier.train()\n",
    "        \n",
    "        insertion_input, deletion_input = self.sample(bs=10)\n",
    "        \n",
    "        preds_deletes = self.d_classifier(self.embedder(deletion_input.to_delete.cuda()).cuda())\n",
    "        preds_placeholders = self.p_classifier(self.embedder(insertion_input.deleted.cuda()))\n",
    "        preds_inserts = self.t_classifier(deletion_input.with_tokens.cuda())\n",
    "        \n",
    "        loss = self.d_loss(torch.transpose(preds_deletes, 1, 2).cuda(), deletion_input.to_delete.cuda())\n",
    "        loss += self.p_loss(torch.transpose(preds_placeholders, 1, 2).cuda(), insertion_input.num_placeholders.cuda())\n",
    "        loss += self.t_loss(torch.transpose(preds_inserts,1,2).cuda(), deletion_input.ground_padded.cuda())\n",
    "        \n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % 250 == 0:\n",
    "            #print(\"t_classifier loss\")\n",
    "            #print(deletion_input.ground_padded)\n",
    "            print(\"preds_placeholders\")\n",
    "            print(preds_placeholders)\n",
    "            print(\"Step %d\" % self.step)\n",
    "            self.pretty_print(\"Ground\", insertion_input.ground[0])\n",
    "            self.pretty_print(\"Input to deletion classifier\", deletion_input.with_tokens[0])\n",
    "            self.pretty_print(\"Expected deletion classifier output\", apply_deletion(deletion_input.with_tokens[0], deletion_input.to_delete[0]))\n",
    "            self.pretty_print(\"Input to placeholder classifier\", insertion_input.deleted[0])\n",
    "            self.pretty_print(\"Expected placeholder classifier output\", placeholders_from_mask(insertion_input.deleted[0], insertion_input.num_placeholders[0])[0])\n",
    "            self.pretty_print(\"Input to insertion classifier\", insertion_input.placeholders[0])\n",
    "            self.pretty_print(\"Expected insertion classifier output\", deletion_input.ground_padded[0])\n",
    "        if self.step % 500 == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.decode_step()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "model = Model(len(tokenizer))\n",
    "#for i in range(100000):\n",
    "#    model.train_step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected sequence of length 150 at dim 1 (got 151)\n",
      "preds_placeholders\n",
      "tensor([[[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         ...,\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         ...,\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 0.9581, -0.7749],\n",
      "         [ 1.2931, -1.1608],\n",
      "         [ 1.2100, -0.8166],\n",
      "         ...,\n",
      "         [ 2.7497, -2.8278],\n",
      "         [ 2.7351, -2.6512],\n",
      "         [ 2.9224, -2.9334]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9684, -0.6771],\n",
      "         [ 1.3518, -1.0064],\n",
      "         [ 1.6863, -1.2080],\n",
      "         ...,\n",
      "         [ 2.9021, -3.0094],\n",
      "         [ 3.0588, -3.2749],\n",
      "         [ 3.0451, -3.0840]],\n",
      "\n",
      "        [[ 1.0137, -0.9241],\n",
      "         [ 2.0261, -2.0036],\n",
      "         [ 1.3990, -0.7371],\n",
      "         ...,\n",
      "         [ 2.4952, -2.6275],\n",
      "         [ 2.7997, -2.8215],\n",
      "         [ 2.8552, -2.9782]],\n",
      "\n",
      "        [[ 1.0896, -1.1210],\n",
      "         [ 1.4336, -0.9834],\n",
      "         [ 1.3654, -0.8138],\n",
      "         ...,\n",
      "         [ 3.0538, -2.9617],\n",
      "         [ 2.6966, -2.4152],\n",
      "         [ 2.9392, -2.7501]]], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "Step 250\n",
      "Ground \n",
      "  <s>what is the german bratwurst? </s>                     \n",
      "Input to deletion classifier \n",
      "  <s>what is the german bratwurst? </s>   <PLH>   <PLH>                                                                                 \n",
      "Expected deletion classifier output \n",
      "  <s>what is the german bratwurst? </s>                                                                                       </s>\n",
      "Input to placeholder classifier \n",
      "  <s> is the german brat rst? </s>                                                                                         \n",
      "Expected placeholder classifier output \n",
      "  <s> is the german <PLH>brat rst? </s>                <PLH>                      \n",
      "Input to insertion classifier \n",
      "  <s> <PLH>is the german brat <PLH>##rst? </s>                 <PLH>   \n",
      "Expected insertion classifier output \n",
      "  <s>what is the german bratwurst? </s>                                                                                         \n",
      "expected sequence of length 189 at dim 1 (got 191)\n",
      "expected sequence of length 102 at dim 1 (got 101)\n",
      "preds_placeholders\n",
      "tensor([[[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         ...,\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         ...,\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 0.7933, -1.0947],\n",
      "         [ 1.5594, -1.5848],\n",
      "         [ 1.1531, -1.0331],\n",
      "         ...,\n",
      "         [ 2.6779, -3.0777],\n",
      "         [ 2.6520, -3.1927],\n",
      "         [ 2.3780, -2.9678]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3148, -1.4961],\n",
      "         [ 1.5603, -1.2250],\n",
      "         [ 1.4982, -1.3174],\n",
      "         ...,\n",
      "         [ 2.6785, -3.0127],\n",
      "         [ 2.5523, -2.8019],\n",
      "         [ 2.6129, -2.7912]],\n",
      "\n",
      "        [[ 0.7900, -0.9772],\n",
      "         [ 1.0138, -1.0492],\n",
      "         [ 1.2434, -1.2317],\n",
      "         ...,\n",
      "         [ 2.6674, -3.0345],\n",
      "         [ 2.4541, -2.7224],\n",
      "         [ 2.4093, -2.8754]],\n",
      "\n",
      "        [[ 1.2729, -1.6289],\n",
      "         [ 1.0444, -0.8702],\n",
      "         [ 1.2501, -1.2789],\n",
      "         ...,\n",
      "         [ 2.7378, -3.1675],\n",
      "         [ 2.3839, -2.5915],\n",
      "         [ 2.3974, -2.6730]]], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "Step 500\n",
      "Ground \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s>              \n",
      "Input to deletion classifier \n",
      "  <s>in which month of the 1789 was the storming of the bastille </s>? </s>  <PLH>       <PLH>                                                                     \n",
      "Expected deletion classifier output \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s>                                                                              </s>\n",
      "Input to placeholder classifier \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s>                                                                                  \n",
      "Expected placeholder classifier output \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s>       <PLH>    <PLH>                    \n",
      "Input to insertion classifier \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s> <PLH>       <PLH> <PLH>   <PLH>\n",
      "Expected insertion classifier output \n",
      "  <s>in which month of 1789 was the storming of the bastille? </s>                                                                                  \n",
      "500\n",
      "tensor(69.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Last \n",
      "  <s>in a hit film from the summer of 2008, robert downey jr. played a man made of what? </s>                                                                           \n",
      "Decode step 0\n",
      "Post-deletion \n",
      "  <s>in hit from the summer 2008, robert downey jr. played a man made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer 2008, robert downey jr. played a man made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer 2008, robert downey jr. played a man made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer 2008, robert downey jr. played a man made? </s>\n",
      "Decode step 1\n",
      "Post-deletion \n",
      "  <s>in hit from the summer,ey made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Decode step 2\n",
      "Post-deletion \n",
      "  <s>in hit from the summer,ey made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Decode step 3\n",
      "Post-deletion \n",
      "  <s>in hit from the summer,ey made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Decode step 4\n",
      "Post-deletion \n",
      "  <s>in hit from the summer,ey made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Decode step 5\n",
      "Post-deletion \n",
      "  <s>in hit from the summer,ey made? </s>                                                                           </s>\n",
      "Post-placeholders \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Post-insert \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      "Last \n",
      "  <s>in hit from the summer,ey made? </s>\n",
      " <s>in hit from the summer,ey made? </s>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-575ec55208bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b678fba5caf3>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    try:\n",
    "        model.train_step()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decode_step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
